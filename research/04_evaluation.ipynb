{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"]=<url>\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"]=<username>\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=<password/token>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn \n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    path_of_model: Path\n",
    "    path_of_stemmer: Path\n",
    "    path_of_stopwords: Path\n",
    "    path_of_vectorizer: Path\n",
    "    training_data: Path\n",
    "    all_params: dict\n",
    "    mlflow_uri: str\n",
    "    params_image_size: list\n",
    "    params_batch_size: int\n",
    "    params_data_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment_analysis.constants import *\n",
    "from sentiment_analysis.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        eval_config = EvaluationConfig(\n",
    "            path_of_model=Path(self.config.training.trained_model_path),\n",
    "            path_of_stemmer=Path(self.config.training.trained_stemmer_path),\n",
    "            path_of_stopwords=Path(self.config.training.trained_stop_words_path),\n",
    "            path_of_vectorizer=Path(self.config.training.trained_vectorizer_path),\n",
    "            training_data=Path(self.config.evaluation.dataset_path),\n",
    "            mlflow_uri=self.config.evaluation.ml_flow_tracking_url,\n",
    "            all_params=self.params,\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_batch_size=self.params.BATCH_SIZE,\n",
    "            params_data_size=self.params.DATA_SIZE\n",
    "        )\n",
    "        return eval_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import mlflow.sklearn\n",
    "from urllib.parse import urlparse\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    def __init__(self, config: EvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    # def _valid_generator(self):\n",
    "\n",
    "    #     datagenerator_kwargs = dict(\n",
    "    #         rescale = 1./255,\n",
    "    #         validation_split=0.30\n",
    "    #     )\n",
    "\n",
    "    #     dataflow_kwargs = dict(\n",
    "    #         target_size=self.config.params_image_size[:-1],\n",
    "    #         batch_size=self.config.params_batch_size,\n",
    "    #         interpolation=\"bilinear\"\n",
    "    #     )\n",
    "\n",
    "    #     valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    #         **datagenerator_kwargs\n",
    "    #     )\n",
    "\n",
    "    #     self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "    #         directory=self.config.training_data,\n",
    "    #         subset=\"validation\",\n",
    "    #         shuffle=False,\n",
    "    #         **dataflow_kwargs\n",
    "    #     )\n",
    "\n",
    "\n",
    "    # @staticmethod\n",
    "    # def load_model(path: Path) -> tf.keras.Model:\n",
    "    #     return tf.keras.models.load_model(path)\n",
    "    def load_model(self):\n",
    "        self.model = pk.load(open(self.config.path_of_model, 'rb'))\n",
    "        self.stopwords = pk.load(open(self.config.path_of_stopwords, 'rb'))\n",
    "        self.stemmer = pk.load(open(self.config.path_of_stemmer, 'rb'))\n",
    "        self.vectorizer = pk.load(open(self.config.path_of_vectorizer, 'rb'))\n",
    "\n",
    "    def data_preprocess(self):\n",
    "        df = pd.read_csv(self.config.training_data)\n",
    "        df = df[['Text', 'Score']]\n",
    "        df = df.sample(n=self.config.params_data_size)\n",
    "        df = df.loc[df['Score']!=3]\n",
    "        df = df.loc[df['Score']!=4]\n",
    "        def category(score):\n",
    "            return 0 if score==1 or score==2 else 1\n",
    "        df['Sentiment']= df['Score'].apply(category)\n",
    "        def text_preprocessing(text):\n",
    "            lower_casing = text.lower()\n",
    "            tokens = word_tokenize(lower_casing)\n",
    "            tokens = [self.stemmer.stem(token) for token in tokens if token not in self.stopwords and token not in string.punctuation]\n",
    "            return \" \".join(tokens)\n",
    "        \n",
    "        df['Text'] = df['Text'].apply(text_preprocessing)\n",
    "        self.y_test = np.array(df['Sentiment'])\n",
    "        self.df = self.vectorizer.transform(df['Text'])\n",
    "    \n",
    "    def evaluation(self):\n",
    "        # self.model = self.load_model(self.config.path_of_model)\n",
    "        self.load_model()\n",
    "        # self._valid_generator()\n",
    "        self.data_preprocess()\n",
    "        self.y_pred = self.model.predict(self.df)\n",
    "        self.score = accuracy_score(self.y_test, self.y_pred)\n",
    "        self.save_score()\n",
    "\n",
    "    def save_score(self):\n",
    "        scores = { \"accuracy\": self.score}\n",
    "        save_json(path=Path(\"scores.json\"), data=scores)\n",
    "\n",
    "    \n",
    "    def log_into_mlflow(self):\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        print(tracking_url_type_store)\n",
    "        \n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics(\n",
    "                { \"accuracy\": self.score}\n",
    "            )\n",
    "            # Model registry does not work with file store\n",
    "            if tracking_url_type_store != \"file\":\n",
    "\n",
    "                # Register the model\n",
    "                # There are other ways to use the Model Registry, which depends on the use case,\n",
    "                # please refer to the doc for more information:\n",
    "                # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "                mlflow.sklearn.log_model(self.model, \"model\", registered_model_name=\"logisticRegression\")\n",
    "            else:\n",
    "                mlflow.sklearn.log_model(self.model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 12:20:23,389: Sentiment-Analysis: INFO: common.py: read_yaml:- yaml file: config/config.yaml loaded successfully\n",
      "2024-08-07 12:20:23,391: Sentiment-Analysis: INFO: common.py: read_yaml:- yaml file: params.yaml loaded successfully\n",
      "2024-08-07 12:20:23,391: Sentiment-Analysis: INFO: common.py: create_directories:- created directory at: artifacts\n",
      "2024-08-07 12:20:51,025: Sentiment-Analysis: INFO: common.py: save_json:- json file saved at: scores.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'logisticRegression'.\n",
      "2024/08/07 12:21:00 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: logisticRegression, version 1\n",
      "Created version '1' of model 'logisticRegression'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    eval_config = config.get_evaluation_config()\n",
    "    evaluation = Evaluation(eval_config)\n",
    "    evaluation.evaluation()\n",
    "    evaluation.log_into_mlflow()\n",
    "\n",
    "except Exception as e:\n",
    "   raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
